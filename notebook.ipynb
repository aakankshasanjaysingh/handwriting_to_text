
getting the data and all the necessary text files and functions

import cv2
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
import random
     

#create a folder to store data
!mkdir sample_data/IAM
# copy the zip files that has data to this folder now
!cp -nav "/content/drive/My Drive/Colab Notebooks/OCR on IAM/data/words zips" /content/sample_data/IAM/
     
mkdir: cannot create directory ‘sample_data/IAM’: File exists

# now unzip all the zips
!unzip -nq /content/sample_data/IAM/'words zips'/\*.zip -d /content/sample_data/IAM/'words zips'/
     
8 archives were successfully processed.

# copy the ground truth texts file
!cp -navr "/content/drive/My Drive/Colab Notebooks/OCR on IAM/data/words.txt" "/content/sample_data/IAM/"
     

data_location = '/content/sample_data/IAM/words zips'
words_txt_location = '/content/sample_data/IAM/words.txt'
     

# copy the splits files
!cp -navr "/content/drive/My Drive/Colab Notebooks/OCR on IAM/train_files.txt" "/content/sample_data/IAM/"
!cp -navr "/content/drive/My Drive/Colab Notebooks/OCR on IAM/valid_files.txt" "/content/sample_data/IAM/"
!cp -navr "/content/drive/My Drive/Colab Notebooks/OCR on IAM/test_files.txt" "/content/sample_data/IAM/"
     

def get_paths_and_gts(partition_split_file):
    """
    read a string like(which can be found in each line of words.txt file):
    'a01-000u-00-00 ok 154 408 768 27 51 AT A'
    and extract 'a01-000u-00-00': location of the image with sub-folders, to read it from the directories
                'ok'            : processing status. ok means good, presumably.
                'A'             : ground truth text

    Then, pre-process using function defined above
    """
    # a list to store paths to images and ground truth texts
    paths_and_gts = []
    
    # open the file
    with open(partition_split_file) as f:
        # go through each line
        for line in f:
            # if a line is empty or commented with #, ignore that line
            if not line or line.startswith('#'):
                continue
            
            # in the text file, each line is seperated with '\n', so `strip` first
            # then string like 'a01-000u-00-00 ok 154 408 768 27 51 AT A' has to split to a list by spaces
            line_split = line.strip().split(' ')
            
            # the first item of the list contains path information, so split that by '-'
            directory_split = line_split[0].split('-')
            
            # now use all the above and concatenate to a string to make a path to an image
            image_location = f'{data_location}/{directory_split[0]}/{directory_split[0]}-{directory_split[1]}/{line_split[0]}.png'
            
            # in a string like 'a01-000u-00-00 ok 154 408 768 27 51 AT A', text from 9th split is the ground truth text.
            gt_text = ' '.join(line_split[8:])
            
            # ignore a sample(image and ground truth text), if the ground truth has more than 16 letters
            # if len(gt_text) > 16:
                # continue
            
            # now, append the image location and ground truth text of that image as a list to 
            paths_and_gts.append([image_location, gt_text])
    
    return paths_and_gts
     
pre-processing

def add_padding(img, old_w, old_h, new_w, new_h):
    h1, h2 = int((new_h - old_h) / 2), int((new_h - old_h) / 2) + old_h
    w1, w2 = int((new_w - old_w) / 2), int((new_w - old_w) / 2) + old_w
    img_pad = np.ones([new_h, new_w, 3]) * 255
    img_pad[h1:h2, w1:w2, :] = img
    return img_pad


def fix_size(img, target_w, target_h):
    h, w = img.shape[:2]
    if w < target_w and h < target_h:
        img = add_padding(img, w, h, target_w, target_h)
    elif w >= target_w and h < target_h:
        new_w = target_w
        new_h = int(h * new_w / w)
        new_img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
        img = add_padding(new_img, new_w, new_h, target_w, target_h)
    elif w < target_w and h >= target_h:
        new_h = target_h
        new_w = int(w * new_h / h)
        new_img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
        img = add_padding(new_img, new_w, new_h, target_w, target_h)
    else:
        """w>=target_w and h>=target_h """
        ratio = max(w / target_w, h / target_h)
        new_w = max(min(target_w, int(w / ratio)), 1)
        new_h = max(min(target_h, int(h / ratio)), 1)
        new_img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
        img = add_padding(new_img, new_w, new_h, target_w, target_h)
    return img


def preprocess(path, img_w, img_h):
    """ Pre-processing image for predicting """
    img = cv2.imread(path)
    img = fix_size(img, img_w, img_h)

    img = np.clip(img, 0, 255)
    img = np.uint8(img)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    img = img.astype(np.float32)
    img /= 255
    return img
     

letters = [' ', '!', '"', '#', '&', "'", '(', ')', '*', '+', ',', '-', '.', '/',
           '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?',
           'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',
           'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',
           'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',
           'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']

num_classes = len(letters) + 1
print(num_classes)
     
80
generating all the pre-processed vectors

def text_to_labels(text):
    return list(map(lambda x: letters.index(x), text))

def labels_to_text(labels):
    return ''.join(list(map(lambda x: letters[int(x)], labels)))
     

train_files = get_paths_and_gts('/content/sample_data/IAM/train_files.txt')
valid_files = get_paths_and_gts('/content/sample_data/IAM/valid_files.txt')
test_files = get_paths_and_gts('/content/sample_data/IAM/test_files.txt')
len(train_files), len(valid_files), len(test_files)
     
(87292, 4316, 4316)

# since this image is not readable is not readable, it has to be discarded.
# ../words/r06/r06-022/r06-022-03-05.png'

for index, (img_loc, gt_text) in enumerate(train_files):
    if 'r06-022-03-05' in img_loc:
        print(index)
    else:
        continue
     
4576

train_files[4576]
     
['/content/sample_data/IAM/words zips/r06/r06-022/r06-022-03-05.png', 'more']

del train_files[4576]
print(train_files[4576])
     
['/content/sample_data/IAM/words zips/g06/g06-042e/g06-042e-05-03.png', 'notice']
this is how images used for training will look like.


i = 21
print(train_files[i][1])
an_img = preprocess(path=train_files[i][0], img_w=128, img_h=64)
plt.imshow(an_img.T)
     
CITIZENS
<matplotlib.image.AxesImage at 0x7f170399fac8>


class TextImageGenerator:
    
    def __init__(self, data,
                 img_w,
                 img_h, 
                 batch_size, 
                 i_len,
                 max_text_len):
        
        self.img_h = img_h
        self.img_w = img_w
        self.batch_size = batch_size
        self.max_text_len = max_text_len
        self.samples = data
        self.n = len(self.samples)
        self.i_len = i_len
        self.indexes = list(range(self.n))
        self.cur_index = 0
        
    def build_data(self):
        self.imgs = np.zeros((self.n, self.img_h, self.img_w))
        self.texts = []
        for i, (img_filepath, text) in enumerate(self.samples):
            img = preprocess(img_filepath, self.img_w, self.img_h)
            self.imgs[i, :, :] = img
            self.texts.append(text)
    
    def next_sample(self):
        self.cur_index += 1
        if self.cur_index >= self.n:
            self.cur_index = 0
            random.shuffle(self.indexes)
        return self.imgs[self.indexes[self.cur_index]], self.texts[self.indexes[self.cur_index]]
    
    def next_batch(self):
        while True:
            # width and height are backwards from typical Keras convention
            # because width is the time dimension when it gets fed into the RNN
            X_data = np.ones([self.batch_size, self.img_w, self.img_h, 1])
            Y_data = np.zeros([self.batch_size, self.max_text_len])
            input_length = np.ones((self.batch_size, 1)) * self.i_len
            label_length = np.zeros((self.batch_size, 1))
                                   
            for i in range(self.batch_size):
                img, text = self.next_sample()
                img = img.T
                img = np.expand_dims(img, -1)
                X_data[i] = img
                Y_data[i, :len(text)] = text_to_labels(text)
                label_length[i] = len(text)
                
            inputs = [X_data, Y_data, input_length, label_length]
            outputs = np.zeros([self.batch_size])
            yield (inputs, outputs)
     

batch_size = 64
input_length = 30
max_text_len = 16
img_w = 128
img_h = 64
     

train_data = TextImageGenerator(train_files, img_w, img_h, batch_size, input_length, max_text_len)
train_data.build_data()
     

train_data.imgs.shape
     
(87291, 64, 128)

validation_data = TextImageGenerator(valid_files, img_w, img_h, batch_size, input_length, max_text_len)
validation_data.build_data()
     
making model

from tensorflow.keras import layers
from tensorflow.keras import Model
from tensorflow.keras import backend as tf_keras_backend

tf_keras_backend.set_image_data_format('channels_last')
tf_keras_backend.image_data_format()
     
'channels_last'

# input_data = layers.Input(name='the_input', shape=(128,64,1), dtype='float32')  # (None, 128, 64, 1)

# # Convolution layer (VGG)
# iam_layers = layers.Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)
# iam_layers = layers.BatchNormalization()(iam_layers)
# iam_layers = layers.Activation('relu')(iam_layers)
# iam_layers = layers.MaxPooling2D(pool_size=(2, 2), name='max1')(iam_layers)  # (None,64, 32, 64)

# iam_layers = layers.Conv2D(128, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(iam_layers)
# iam_layers = layers.BatchNormalization()(iam_layers)
# iam_layers = layers.Activation('relu')(iam_layers)
# iam_layers = layers.MaxPooling2D(pool_size=(2, 2), name='max2')(iam_layers)

# iam_layers = layers.Conv2D(256, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(iam_layers)
# iam_layers = layers.BatchNormalization()(iam_layers)
# iam_layers = layers.Activation('relu')(iam_layers)
# iam_layers = layers.Conv2D(256, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(iam_layers)
# iam_layers = layers.BatchNormalization()(iam_layers)
# iam_layers = layers.Activation('relu')(iam_layers)
# iam_layers = layers.MaxPooling2D(pool_size=(1, 2), name='max3')(iam_layers)  # (None, 32, 8, 256)

# iam_layers = layers.Conv2D(512, (3, 3), padding='same', name='conv5', kernel_initializer='he_normal')(iam_layers)
# iam_layers = layers.BatchNormalization()(iam_layers)
# iam_layers = layers.Activation('relu')(iam_layers)
# iam_layers = layers.Conv2D(512, (3, 3), padding='same', name='conv6')(iam_layers)
# iam_layers = layers.BatchNormalization()(iam_layers)
# iam_layers = layers.Activation('relu')(iam_layers)
# iam_layers = layers.MaxPooling2D(pool_size=(1, 2), name='max4')(iam_layers)

# iam_layers = layers.Conv2D(512, (2, 2), padding='same', kernel_initializer='he_normal', name='con7')(iam_layers)
# iam_layers = layers.BatchNormalization()(iam_layers)
# iam_layers = layers.Activation('relu')(iam_layers)

# # CNN to RNN
# iam_layers = layers.Reshape(target_shape=((32, 2048)), name='reshape')(iam_layers)
# iam_layers = layers.Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(iam_layers)

# # RNN layer
# gru_1 = layers.GRU(256, return_sequences=True, kernel_initializer='he_normal', name='gru1')(iam_layers)
# gru_1b = layers.GRU(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(iam_layers)
# reversed_gru_1b = layers.Lambda(lambda inputTensor: tf_keras_backend.reverse(inputTensor, axes=1)) (gru_1b)

# gru1_merged = layers.add([gru_1, reversed_gru_1b])
# gru1_merged = layers.BatchNormalization()(gru1_merged)

# gru_2 = layers.GRU(256, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)
# gru_2b = layers.GRU(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)
# reversed_gru_2b= layers.Lambda(lambda inputTensor: tf_keras_backend.reverse(inputTensor, axes=1)) (gru_2b)

# gru2_merged = layers.concatenate([gru_2, reversed_gru_2b])
# gru2_merged = layers.BatchNormalization()(gru2_merged)

# # transforms RNN output to character activations:
# iam_layers = layers.Dense(80, kernel_initializer='he_normal', name='dense2')(gru2_merged)
# iam_outputs = layers.Activation('softmax', name='softmax')(iam_layers)

# labels = layers.Input(name='the_labels', shape=[16], dtype='float32')
# input_length = layers.Input(name='input_length', shape=[1], dtype='int64')
# label_length = layers.Input(name='label_length', shape=[1], dtype='int64')


# def ctc_lambda_func(args):
#     y_pred, labels, input_length, label_length = args
#     # the 2 is critical here since the first couple outputs of the RNN
#     # tend to be garbage:
#     y_pred = y_pred[:, 2:, :]
#     return tf_keras_backend.ctc_batch_cost(labels, y_pred, input_length, label_length)


# # loss function
# loss_out = layers.Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([iam_outputs, labels, input_length, label_length])

# model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)
model.summary()
     
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
the_input (InputLayer)          [(None, 128, 64, 1)] 0                                            
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 128, 64, 64)  640         the_input[0][0]                  
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 128, 64, 64)  256         conv1[0][0]                      
__________________________________________________________________________________________________
activation (Activation)         (None, 128, 64, 64)  0           batch_normalization[0][0]        
__________________________________________________________________________________________________
max1 (MaxPooling2D)             (None, 64, 32, 64)   0           activation[0][0]                 
__________________________________________________________________________________________________
conv2 (Conv2D)                  (None, 64, 32, 128)  73856       max1[0][0]                       
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 64, 32, 128)  512         conv2[0][0]                      
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 32, 128)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
max2 (MaxPooling2D)             (None, 32, 16, 128)  0           activation_1[0][0]               
__________________________________________________________________________________________________
conv3 (Conv2D)                  (None, 32, 16, 256)  295168      max2[0][0]                       
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 16, 256)  1024        conv3[0][0]                      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 16, 256)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv4 (Conv2D)                  (None, 32, 16, 256)  590080      activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 16, 256)  1024        conv4[0][0]                      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 16, 256)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max3 (MaxPooling2D)             (None, 32, 8, 256)   0           activation_3[0][0]               
__________________________________________________________________________________________________
conv5 (Conv2D)                  (None, 32, 8, 512)   1180160     max3[0][0]                       
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 8, 512)   2048        conv5[0][0]                      
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 8, 512)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv6 (Conv2D)                  (None, 32, 8, 512)   2359808     activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 8, 512)   2048        conv6[0][0]                      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 8, 512)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
max4 (MaxPooling2D)             (None, 32, 4, 512)   0           activation_5[0][0]               
__________________________________________________________________________________________________
con7 (Conv2D)                   (None, 32, 4, 512)   1049088     max4[0][0]                       
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 4, 512)   2048        con7[0][0]                       
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 4, 512)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
reshape (Reshape)               (None, 32, 2048)     0           activation_6[0][0]               
__________________________________________________________________________________________________
dense1 (Dense)                  (None, 32, 64)       131136      reshape[0][0]                    
__________________________________________________________________________________________________
gru1_b (GRU)                    (None, 32, 256)      247296      dense1[0][0]                     
__________________________________________________________________________________________________
gru1 (GRU)                      (None, 32, 256)      247296      dense1[0][0]                     
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 32, 256)      0           gru1_b[0][0]                     
__________________________________________________________________________________________________
add (Add)                       (None, 32, 256)      0           gru1[0][0]                       
                                                                 lambda[0][0]                     
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 256)      1024        add[0][0]                        
__________________________________________________________________________________________________
gru2_b (GRU)                    (None, 32, 256)      394752      batch_normalization_7[0][0]      
__________________________________________________________________________________________________
gru2 (GRU)                      (None, 32, 256)      394752      batch_normalization_7[0][0]      
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 32, 256)      0           gru2_b[0][0]                     
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 32, 512)      0           gru2[0][0]                       
                                                                 lambda_1[0][0]                   
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 512)      2048        concatenate[0][0]                
__________________________________________________________________________________________________
dense2 (Dense)                  (None, 32, 80)       41040       batch_normalization_8[0][0]      
__________________________________________________________________________________________________
softmax (Activation)            (None, 32, 80)       0           dense2[0][0]                     
__________________________________________________________________________________________________
the_labels (InputLayer)         [(None, 16)]         0                                            
__________________________________________________________________________________________________
input_length (InputLayer)       [(None, 1)]          0                                            
__________________________________________________________________________________________________
label_length (InputLayer)       [(None, 1)]          0                                            
__________________________________________________________________________________________________
ctc (Lambda)                    (None, 1)            0           softmax[0][0]                    
                                                                 the_labels[0][0]                 
                                                                 input_length[0][0]               
                                                                 label_length[0][0]               
==================================================================================================
Total params: 7,017,104
Trainable params: 7,011,088
Non-trainable params: 6,016
__________________________________________________________________________________________________

model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = 'adam')
# you will know, why there aren't any metrics
     

import time
from tensorflow.keras.callbacks import Callback
from datetime import datetime

class EpochTimeHistory(Callback):
    """
    a custom callback to print the time(in minutes, to console) each epoch took during.
    """
    def on_train_begin(self, logs={}):
        self.train_epoch_times = []
        self.valid_epoch_times = []
    
    def on_epoch_begin(self, epoch, logs={}):
        self.epoch_time_start = time.time()

    def on_epoch_end(self, epoch, logs={}):
            cur_epoch_time = round((time.time() - self.epoch_time_start)/60, 4)
            self.train_epoch_times.append(cur_epoch_time )
            # cur_epoch_time = datetime.strptime(str(cur_epoch_time), "%H:%M:%S.%f").strftime('%H:%M:%S')
            self.train_epoch_times.append(cur_epoch_time)
            print(" ;epoch {0} took {1} minutes.".format(epoch+1, cur_epoch_time))
    
    ## functions used below are for recording validation times
    def on_test_begin(self, logs={}):
        self.test_time_start = time.time()

    def on_test_end(self, logs={}):
        cur_test_time = round((time.time() - self.test_time_start)/60, 4)
        self.valid_epoch_times.append(cur_test_time)
        # cur_test_time = datetime.strptime(str(cur_test_time), "%H:%M:%S.%f").strftime('%H:%M:%S')
        print(" ;validation took {0} minutes.".format(cur_test_time))
     

from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

model_save_cb = ModelCheckpoint(filepath='/content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch{epoch:02d}-val_loss{val_loss:.3f}.h5',
                                verbose=1, save_best_only=False, monitor='val_loss', save_weights_only=False)
earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min')
# reduce_learning_rate_cb = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=2, cooldown=2, min_lr=0.00001, verbose=1)
epoch_times = EpochTimeHistory()
     

batch_size, train_data.n, validation_data.n
     
(64, 87291, 4316)

history_model_3 = model.fit(train_data.next_batch(),
                            validation_data=validation_data.next_batch(),
                            steps_per_epoch=train_data.n/batch_size,
                            validation_steps=validation_data.n // batch_size,
                            epochs=30, verbose=1,
                            callbacks=[earlystop, model_save_cb, epoch_times])
     
Epoch 1/30
1364/1363 [==============================] - ETA: 0s - loss: 9.8086 ;validation took 0.159

Epoch 00001: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch01-val_loss5.180.h5
 ;epoch 1 took 6.9442
1364/1363 [==============================] - 404s 296ms/step - loss: 9.8086 - val_loss: 5.1796
Epoch 2/30
1364/1363 [==============================] - ETA: 0s - loss: 3.3045 ;validation took 0.1292

Epoch 00002: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch02-val_loss2.696.h5
 ;epoch 2 took 6.7038
1364/1363 [==============================] - 402s 295ms/step - loss: 3.3045 - val_loss: 2.6962
Epoch 3/30
1364/1363 [==============================] - ETA: 0s - loss: 2.1474 ;validation took 0.1294

Epoch 00003: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch03-val_loss2.115.h5
 ;epoch 3 took 6.7038
1364/1363 [==============================] - 402s 295ms/step - loss: 2.1474 - val_loss: 2.1149
Epoch 4/30
1364/1363 [==============================] - ETA: 0s - loss: 1.7019 ;validation took 0.129

Epoch 00004: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch04-val_loss1.702.h5
 ;epoch 4 took 6.6937
1364/1363 [==============================] - 401s 294ms/step - loss: 1.7019 - val_loss: 1.7020
Epoch 5/30
1364/1363 [==============================] - ETA: 0s - loss: 1.4354 ;validation took 0.1292

Epoch 00005: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch05-val_loss1.394.h5
 ;epoch 5 took 6.6866
1364/1363 [==============================] - 401s 294ms/step - loss: 1.4354 - val_loss: 1.3942
Epoch 6/30
1364/1363 [==============================] - ETA: 0s - loss: 1.2140 ;validation took 0.1295

Epoch 00006: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch06-val_loss1.189.h5
 ;epoch 6 took 6.6907
1364/1363 [==============================] - 401s 294ms/step - loss: 1.2140 - val_loss: 1.1894
Epoch 7/30
1364/1363 [==============================] - ETA: 0s - loss: 1.0513 ;validation took 0.128

Epoch 00007: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch07-val_loss1.942.h5
 ;epoch 7 took 6.6815
1364/1363 [==============================] - 401s 294ms/step - loss: 1.0513 - val_loss: 1.9418
Epoch 8/30
1364/1363 [==============================] - ETA: 0s - loss: 0.9217 ;validation took 0.129

Epoch 00008: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch08-val_loss1.321.h5
 ;epoch 8 took 6.684
1364/1363 [==============================] - 401s 294ms/step - loss: 0.9217 - val_loss: 1.3213
Epoch 9/30
1364/1363 [==============================] - ETA: 0s - loss: 0.8147 ;validation took 0.1286

Epoch 00009: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch09-val_loss1.047.h5
 ;epoch 9 took 6.6816
1364/1363 [==============================] - 401s 294ms/step - loss: 0.8147 - val_loss: 1.0472
Epoch 10/30
1364/1363 [==============================] - ETA: 0s - loss: 0.7184 ;validation took 0.1292

Epoch 00010: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch10-val_loss0.776.h5
 ;epoch 10 took 6.6767
1364/1363 [==============================] - 400s 293ms/step - loss: 0.7184 - val_loss: 0.7764
Epoch 11/30
1364/1363 [==============================] - ETA: 0s - loss: 0.6444 ;validation took 0.129

Epoch 00011: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch11-val_loss0.810.h5
 ;epoch 11 took 6.6804
1364/1363 [==============================] - 401s 294ms/step - loss: 0.6444 - val_loss: 0.8100
Epoch 12/30
1364/1363 [==============================] - ETA: 0s - loss: 0.5471 ;validation took 0.1291

Epoch 00012: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch12-val_loss0.618.h5
 ;epoch 12 took 6.7108
1364/1363 [==============================] - 402s 295ms/step - loss: 0.5471 - val_loss: 0.6176
Epoch 13/30
1364/1363 [==============================] - ETA: 0s - loss: 0.4968 ;validation took 0.1302

Epoch 00013: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch13-val_loss0.606.h5
 ;epoch 13 took 6.7117
1364/1363 [==============================] - 402s 295ms/step - loss: 0.4968 - val_loss: 0.6056
Epoch 14/30
1364/1363 [==============================] - ETA: 0s - loss: 0.4569 ;validation took 0.1297

Epoch 00014: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch14-val_loss0.603.h5
 ;epoch 14 took 6.7027
1364/1363 [==============================] - 402s 295ms/step - loss: 0.4569 - val_loss: 0.6030
Epoch 15/30
1364/1363 [==============================] - ETA: 0s - loss: 0.4167 ;validation took 0.1296

Epoch 00015: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch15-val_loss0.666.h5
 ;epoch 15 took 6.7053
1364/1363 [==============================] - 402s 295ms/step - loss: 0.4167 - val_loss: 0.6659
Epoch 16/30
1364/1363 [==============================] - ETA: 0s - loss: 0.3855 ;validation took 0.1311

Epoch 00016: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch16-val_loss0.488.h5
 ;epoch 16 took 6.7095
1364/1363 [==============================] - 402s 295ms/step - loss: 0.3855 - val_loss: 0.4884
Epoch 17/30
1364/1363 [==============================] - ETA: 0s - loss: 0.3615 ;validation took 0.1293

Epoch 00017: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch17-val_loss0.646.h5
 ;epoch 17 took 6.6735
1364/1363 [==============================] - 400s 293ms/step - loss: 0.3615 - val_loss: 0.6460
Epoch 18/30
1364/1363 [==============================] - ETA: 0s - loss: 0.3508 ;validation took 0.1296

Epoch 00018: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch18-val_loss0.462.h5
 ;epoch 18 took 6.7172
1364/1363 [==============================] - 403s 295ms/step - loss: 0.3508 - val_loss: 0.4622
Epoch 19/30
1364/1363 [==============================] - ETA: 0s - loss: 0.3235 ;validation took 0.1309

Epoch 00019: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch19-val_loss1.001.h5
 ;epoch 19 took 6.7036
1364/1363 [==============================] - 402s 295ms/step - loss: 0.3235 - val_loss: 1.0012
Epoch 20/30
1364/1363 [==============================] - ETA: 0s - loss: 0.3215 ;validation took 0.1309

Epoch 00020: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch20-val_loss0.422.h5
 ;epoch 20 took 6.74
1364/1363 [==============================] - 404s 296ms/step - loss: 0.3215 - val_loss: 0.4224
Epoch 21/30
1364/1363 [==============================] - ETA: 0s - loss: 0.2877 ;validation took 0.13

Epoch 00021: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch21-val_loss1.108.h5
 ;epoch 21 took 6.7254
1364/1363 [==============================] - 403s 296ms/step - loss: 0.2877 - val_loss: 1.1076
Epoch 22/30
1364/1363 [==============================] - ETA: 0s - loss: 0.2935 ;validation took 0.1303

Epoch 00022: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch22-val_loss0.541.h5
 ;epoch 22 took 6.7002
1364/1363 [==============================] - 402s 295ms/step - loss: 0.2935 - val_loss: 0.5407
Epoch 23/30
1364/1363 [==============================] - ETA: 0s - loss: 0.2718 ;validation took 0.1304

Epoch 00023: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch23-val_loss0.561.h5
 ;epoch 23 took 6.6793
1364/1363 [==============================] - 400s 294ms/step - loss: 0.2718 - val_loss: 0.5614
Epoch 24/30
1364/1363 [==============================] - ETA: 0s - loss: 0.2570 ;validation took 0.1298

Epoch 00024: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch24-val_loss6.555.h5
 ;epoch 24 took 6.7281
1364/1363 [==============================] - 403s 296ms/step - loss: 0.2570 - val_loss: 6.5554
Epoch 25/30
1364/1363 [==============================] - ETA: 0s - loss: 0.2521 ;validation took 0.1302

Epoch 00025: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch25-val_loss0.609.h5
 ;epoch 25 took 6.7266
1364/1363 [==============================] - 403s 296ms/step - loss: 0.2521 - val_loss: 0.6089
Epoch 26/30
1364/1363 [==============================] - ETA: 0s - loss: 0.2471 ;validation took 0.1271

Epoch 00026: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch26-val_loss0.533.h5
 ;epoch 26 took 6.7043
1364/1363 [==============================] - 402s 295ms/step - loss: 0.2471 - val_loss: 0.5334
Epoch 27/30
1364/1363 [==============================] - ETA: 0s - loss: 0.2395 ;validation took 0.1289

Epoch 00027: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch27-val_loss2.249.h5
 ;epoch 27 took 6.7095
1364/1363 [==============================] - 402s 295ms/step - loss: 0.2395 - val_loss: 2.2487
Epoch 28/30
1364/1363 [==============================] - ETA: 0s - loss: 0.2365 ;validation took 0.1285

Epoch 00028: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch28-val_loss0.421.h5
 ;epoch 28 took 6.7089
1364/1363 [==============================] - 402s 295ms/step - loss: 0.2365 - val_loss: 0.4208
Epoch 29/30
1364/1363 [==============================] - ETA: 0s - loss: 0.2224 ;validation took 0.1301

Epoch 00029: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch29-val_loss0.447.h5
 ;epoch 29 took 6.7033
1364/1363 [==============================] - 402s 295ms/step - loss: 0.2224 - val_loss: 0.4471
Epoch 30/30
1364/1363 [==============================] - ETA: 0s - loss: 0.2128 ;validation took 0.1314

Epoch 00030: saving model to /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch30-val_loss0.449.h5
 ;epoch 30 took 6.7075
1364/1363 [==============================] - 402s 295ms/step - loss: 0.2128 - val_loss: 0.4485

model.save(filepath='/content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-model-after-4th-session.h5', overwrite=False, include_optimizer=True)
     
[WARNING] /content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-model-after-4th-session.h5 already exists - overwrite? [y/n]y
[TIP] Next time specify overwrite=True!
plotting model statistics

import seaborn as sns
     
/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.
  import pandas.util.testing as tm

sns.set(rc={'figure.figsize':(14,7)})
plt.plot(history_model_3.history['loss'])
plt.plot(history_model_3.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='best')
plt.show()
     


history_model_3.history.keys()
     
dict_keys(['loss', 'val_loss'])

import pandas as pd
     

loss_df = pd.DataFrame(data=history_model_3.history)
loss_df.head()
     
loss	val_loss
0	9.808599	5.179650
1	3.304496	2.696191
2	2.147394	2.114917
3	1.701879	1.701990
4	1.435440	1.394194

loss_df.sort_values(by=['loss', 'val_loss']).head()
     
loss	val_loss
29	0.212780	0.448530
28	0.222380	0.447127
27	0.236462	0.420810
26	0.239505	2.248684
25	0.247085	0.533390

loss_df.sort_values(by=['val_loss', 'loss']).head()
     
loss	val_loss
27	0.236462	0.420810
19	0.321456	0.422444
28	0.222380	0.447127
29	0.212780	0.448530
17	0.350819	0.462215
so, let's use the weights of 30th(labelled 29 above) and 28th(labelled 27 above) epochs.

predictions on test set and calculating WER & CER
make predictions using weights from various checkpoints, since that's the epoch with lowest train and validation error.


sns.reset_orig()
plt.figure(figsize=(3, 6))
i = 1
print(test_files[i][1])
temp_processed_image = preprocess(path=test_files[i][0], img_w=128, img_h=64)
plt.imshow(temp_processed_image.T)
     
biographies
<matplotlib.image.AxesImage at 0x7f165e6340f0>


test_images_processed = []
original_test_texts = []
for _, (test_image_path, original_test_text) in enumerate(test_files):
     temp_processed_image = preprocess(path=test_image_path, img_w=128, img_h=64)
     test_images_processed.append(temp_processed_image.T)
     original_test_texts.append(original_test_text)
     

print(len(test_files))
print(len(test_images_processed))
print(len(original_test_texts))
     
4316
4316
4316

test_images_processed = np.array(test_images_processed)
test_images_processed.shape
     
(4316, 128, 64)

test_images_processed = test_images_processed.reshape(4316, 128, 64, 1)
test_images_processed.shape
     
(4316, 128, 64, 1)

sns.reset_orig()
plt.figure(figsize=(3, 6))
i = 1
print(test_files[i][1])
plt.imshow(test_images_processed[i].reshape(128,64))
     
biographies
<matplotlib.image.AxesImage at 0x7f165e60bb00>

iam with weights of final and 30th epoch. (the one with least loss on train data)

iam_model_pred = Model(inputs=input_data, outputs=iam_outputs)
iam_model_pred.summary()
     
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
the_input (InputLayer)          [(None, 128, 64, 1)] 0                                            
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 128, 64, 64)  640         the_input[0][0]                  
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 128, 64, 64)  256         conv1[0][0]                      
__________________________________________________________________________________________________
activation (Activation)         (None, 128, 64, 64)  0           batch_normalization[0][0]        
__________________________________________________________________________________________________
max1 (MaxPooling2D)             (None, 64, 32, 64)   0           activation[0][0]                 
__________________________________________________________________________________________________
conv2 (Conv2D)                  (None, 64, 32, 128)  73856       max1[0][0]                       
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 64, 32, 128)  512         conv2[0][0]                      
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 32, 128)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
max2 (MaxPooling2D)             (None, 32, 16, 128)  0           activation_1[0][0]               
__________________________________________________________________________________________________
conv3 (Conv2D)                  (None, 32, 16, 256)  295168      max2[0][0]                       
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 16, 256)  1024        conv3[0][0]                      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 16, 256)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv4 (Conv2D)                  (None, 32, 16, 256)  590080      activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 16, 256)  1024        conv4[0][0]                      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 16, 256)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max3 (MaxPooling2D)             (None, 32, 8, 256)   0           activation_3[0][0]               
__________________________________________________________________________________________________
conv5 (Conv2D)                  (None, 32, 8, 512)   1180160     max3[0][0]                       
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 8, 512)   2048        conv5[0][0]                      
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 8, 512)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv6 (Conv2D)                  (None, 32, 8, 512)   2359808     activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 8, 512)   2048        conv6[0][0]                      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 8, 512)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
max4 (MaxPooling2D)             (None, 32, 4, 512)   0           activation_5[0][0]               
__________________________________________________________________________________________________
con7 (Conv2D)                   (None, 32, 4, 512)   1049088     max4[0][0]                       
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 4, 512)   2048        con7[0][0]                       
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 4, 512)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
reshape (Reshape)               (None, 32, 2048)     0           activation_6[0][0]               
__________________________________________________________________________________________________
dense1 (Dense)                  (None, 32, 64)       131136      reshape[0][0]                    
__________________________________________________________________________________________________
gru1_b (GRU)                    (None, 32, 256)      247296      dense1[0][0]                     
__________________________________________________________________________________________________
gru1 (GRU)                      (None, 32, 256)      247296      dense1[0][0]                     
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 32, 256)      0           gru1_b[0][0]                     
__________________________________________________________________________________________________
add (Add)                       (None, 32, 256)      0           gru1[0][0]                       
                                                                 lambda[0][0]                     
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 256)      1024        add[0][0]                        
__________________________________________________________________________________________________
gru2_b (GRU)                    (None, 32, 256)      394752      batch_normalization_7[0][0]      
__________________________________________________________________________________________________
gru2 (GRU)                      (None, 32, 256)      394752      batch_normalization_7[0][0]      
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 32, 256)      0           gru2_b[0][0]                     
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 32, 512)      0           gru2[0][0]                       
                                                                 lambda_1[0][0]                   
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 512)      2048        concatenate[0][0]                
__________________________________________________________________________________________________
dense2 (Dense)                  (None, 32, 80)       41040       batch_normalization_8[0][0]      
__________________________________________________________________________________________________
softmax (Activation)            (None, 32, 80)       0           dense2[0][0]                     
==================================================================================================
Total params: 7,017,104
Trainable params: 7,011,088
Non-trainable params: 6,016
__________________________________________________________________________________________________

iam_model_pred.load_weights(filepath='/content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-model-after-4th-session.h5')
     

test_predictions_encoded = iam_model_pred.predict(x=test_images_processed)
test_predictions_encoded.shape
     
(4316, 32, 80)

# use CTC decoder to decode to text
test_predictions_decoded = tf_keras_backend.get_value(tf_keras_backend.ctc_decode(test_predictions_encoded,
                                                                                  input_length = np.ones(test_predictions_encoded.shape[0])*test_predictions_encoded.shape[1],
                                                                                  greedy=True)[0][0])
test_predictions_decoded.shape
     
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:5871: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
(4316, 14)

def numbered_array_to_text(numbered_array):
    numbered_array = numbered_array[numbered_array != -1]
    return "".join(letters[i] for i in numbered_array)
     

for i in range(10):
    print("original_text = ", original_test_texts[i])
    print("predicted text = ", numbered_array_to_text(test_predictions_decoded[i]))
    print()
     
original_text =  certain
predicted text =  Gcertain

original_text =  biographies
predicted text =  biogrophies

original_text =  all
predicted text =  all

original_text =  It
predicted text =  It

original_text =  I
predicted text =  I1

original_text =  show
predicted text =  show

original_text =  Kings
predicted text =  fKings

original_text =  A
predicted text =  A

original_text =  the
predicted text =  the

original_text =  and
predicted text =  and

with weights of 28th epoch (the one with the least loss of validation data)

iam_model_pred = None
iam_model_pred = Model(inputs=input_data, outputs=iam_outputs)
iam_model_pred.summary()
     
Model: "model_2"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
the_input (InputLayer)          [(None, 128, 64, 1)] 0                                            
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 128, 64, 64)  640         the_input[0][0]                  
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 128, 64, 64)  256         conv1[0][0]                      
__________________________________________________________________________________________________
activation (Activation)         (None, 128, 64, 64)  0           batch_normalization[0][0]        
__________________________________________________________________________________________________
max1 (MaxPooling2D)             (None, 64, 32, 64)   0           activation[0][0]                 
__________________________________________________________________________________________________
conv2 (Conv2D)                  (None, 64, 32, 128)  73856       max1[0][0]                       
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 64, 32, 128)  512         conv2[0][0]                      
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 64, 32, 128)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
max2 (MaxPooling2D)             (None, 32, 16, 128)  0           activation_1[0][0]               
__________________________________________________________________________________________________
conv3 (Conv2D)                  (None, 32, 16, 256)  295168      max2[0][0]                       
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 16, 256)  1024        conv3[0][0]                      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 16, 256)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv4 (Conv2D)                  (None, 32, 16, 256)  590080      activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 16, 256)  1024        conv4[0][0]                      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 16, 256)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max3 (MaxPooling2D)             (None, 32, 8, 256)   0           activation_3[0][0]               
__________________________________________________________________________________________________
conv5 (Conv2D)                  (None, 32, 8, 512)   1180160     max3[0][0]                       
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 8, 512)   2048        conv5[0][0]                      
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 8, 512)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv6 (Conv2D)                  (None, 32, 8, 512)   2359808     activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 8, 512)   2048        conv6[0][0]                      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 8, 512)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
max4 (MaxPooling2D)             (None, 32, 4, 512)   0           activation_5[0][0]               
__________________________________________________________________________________________________
con7 (Conv2D)                   (None, 32, 4, 512)   1049088     max4[0][0]                       
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 4, 512)   2048        con7[0][0]                       
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 4, 512)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
reshape (Reshape)               (None, 32, 2048)     0           activation_6[0][0]               
__________________________________________________________________________________________________
dense1 (Dense)                  (None, 32, 64)       131136      reshape[0][0]                    
__________________________________________________________________________________________________
gru1_b (GRU)                    (None, 32, 256)      247296      dense1[0][0]                     
__________________________________________________________________________________________________
gru1 (GRU)                      (None, 32, 256)      247296      dense1[0][0]                     
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 32, 256)      0           gru1_b[0][0]                     
__________________________________________________________________________________________________
add (Add)                       (None, 32, 256)      0           gru1[0][0]                       
                                                                 lambda[0][0]                     
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 256)      1024        add[0][0]                        
__________________________________________________________________________________________________
gru2_b (GRU)                    (None, 32, 256)      394752      batch_normalization_7[0][0]      
__________________________________________________________________________________________________
gru2 (GRU)                      (None, 32, 256)      394752      batch_normalization_7[0][0]      
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 32, 256)      0           gru2_b[0][0]                     
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 32, 512)      0           gru2[0][0]                       
                                                                 lambda_1[0][0]                   
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 512)      2048        concatenate[0][0]                
__________________________________________________________________________________________________
dense2 (Dense)                  (None, 32, 80)       41040       batch_normalization_8[0][0]      
__________________________________________________________________________________________________
softmax (Activation)            (None, 32, 80)       0           dense2[0][0]                     
==================================================================================================
Total params: 7,017,104
Trainable params: 7,011,088
Non-trainable params: 6,016
__________________________________________________________________________________________________

iam_model_pred.load_weights(filepath='/content/drive/My Drive/Colab Notebooks/OCR on IAM/data/gru-weights-epoch28-val_loss0.421.h5')
     

test_predictions_encoded = None
test_predictions_decoded = None
     

test_predictions_encoded = iam_model_pred.predict(x=test_images_processed)
# use CTC decoder to decode to text
test_predictions_decoded = tf_keras_backend.get_value(tf_keras_backend.ctc_decode(test_predictions_encoded,
                                                                                  input_length = np.ones(test_predictions_encoded.shape[0])*test_predictions_encoded.shape[1],
                                                                                  greedy=True)[0][0])
test_predictions_decoded.shape
     
(4316, 14)

for i in range(10):
    print("original_text = ", original_test_texts[i])
    print("predicted text = ", numbered_array_to_text(test_predictions_decoded[i]))
    print()
     
original_text =  certain
predicted text =  Gcertain

original_text =  biographies
predicted text =  SGhigraphies

original_text =  all
predicted text =  all

original_text =  It
predicted text =  SIt

original_text =  I
predicted text =  SI

original_text =  show
predicted text =  show

original_text =  Kings
predicted text =  Kings

original_text =  A
predicted text =  GA

original_text =  the
predicted text =  the

original_text =  and
predicted text =  and


from google.colab import drive
drive.flush_and_unmount()
     
